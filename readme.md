# RAG Evaluation Pipeline

This repository contains a modular and extensible pipeline for experimenting with **Retrieval-Augmented Generation (RAG)** techniques, focused on educational content and small-scale LLMs.  
The project is designed for testing different components independently â€” retrieval, generation, and evaluation â€” and combining them into complete RAG workflows.

---

## âœ¨ Features

- **Vector Store with Qdrant (embedded mode)**
  - Fast similarity search
  - Persistent, local storage
  - Easy collection and point management

- **Flexible Retriever**
  - SentenceTransformer embeddings
  - Stored and indexed with Qdrant
  - Automatic creation of collections

- **Modular Generator**
  - Supports multiple small LLMs (Gemma, Phi, TinyLlama, etc.)
  - Clean prompt formatting for RAG workflows
  - Extensible enum for different models

- **Evaluation Hooks**
  - Ready for integration with Ragas, LLM-as-a-Judge, or custom metrics

- **Fully Local Execution**
  - No external APIs required
  - Easy experimentation on CPU/GPU

---

## ðŸ“‚ Project Structure

rag-eval/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ retrieval.py # Vector retrieval with Qdrant
â”‚ â”œâ”€â”€ generation.py # LLM generation component
â”‚ â”œâ”€â”€ evaluation_ragas.py # RAGAS evaluation (optional)
â”‚ â”œâ”€â”€ evaluation_judge.py # LLM-judge evaluation (optional)
â”‚ â”œâ”€â”€ vector_db_manager.py # Qdrant storage manager
â”‚ â”œâ”€â”€ pipeline.py # Combined RAG pipeline
â”‚ â””â”€â”€ main.py # Example usage
â”œâ”€â”€ qdrant_data/ # Local Qdrant storage (ignored in Git)
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md

## Run It

```bash
poetry install
poetry run python src/main.py